{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\andre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\andre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\andre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\andre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\andre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords, words\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Download necessary NLTK packages\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accountant</td>\n",
       "      <td>education omba executive leadership university...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accountant</td>\n",
       "      <td>howard gerrard accountant deyjobcom birmingham...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Accountant</td>\n",
       "      <td>kevin frank senior accountant inforesumekraftc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Accountant</td>\n",
       "      <td>place birth nationality olivia ogilvy accounta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accountant</td>\n",
       "      <td>stephen greet cpa senior accountant 9 year exp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Category                                               Text\n",
       "0  Accountant  education omba executive leadership university...\n",
       "1  Accountant  howard gerrard accountant deyjobcom birmingham...\n",
       "2  Accountant  kevin frank senior accountant inforesumekraftc...\n",
       "3  Accountant  place birth nationality olivia ogilvy accounta...\n",
       "4  Accountant  stephen greet cpa senior accountant 9 year exp..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('../dataset/DataSetGitHub/train.csv')\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Resume_str</th>\n",
       "      <th>Resume_html</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16852973</td>\n",
       "      <td>HR ADMINISTRATOR/MARKETING ASSOCIATE\\...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22323967</td>\n",
       "      <td>HR SPECIALIST, US HR OPERATIONS      ...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33176873</td>\n",
       "      <td>HR DIRECTOR       Summary      Over 2...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27018550</td>\n",
       "      <td>HR SPECIALIST       Summary    Dedica...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17812897</td>\n",
       "      <td>HR MANAGER         Skill Highlights  ...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                         Resume_str  \\\n",
       "0  16852973           HR ADMINISTRATOR/MARKETING ASSOCIATE\\...   \n",
       "1  22323967           HR SPECIALIST, US HR OPERATIONS      ...   \n",
       "2  33176873           HR DIRECTOR       Summary      Over 2...   \n",
       "3  27018550           HR SPECIALIST       Summary    Dedica...   \n",
       "4  17812897           HR MANAGER         Skill Highlights  ...   \n",
       "\n",
       "                                         Resume_html Category  \n",
       "0  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
       "1  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
       "2  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
       "3  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
       "4  <div class=\"fontsize fontface vmargins hmargin...       HR  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('../dataset/DataSetKaggle/Resume/Resume.csv')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13389 entries, 0 to 13388\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Category  13389 non-null  object\n",
      " 1   Text      13389 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 209.3+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2484 entries, 0 to 2483\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   ID           2484 non-null   int64 \n",
      " 1   Resume_str   2484 non-null   object\n",
      " 2   Resume_html  2484 non-null   object\n",
      " 3   Category     2484 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 77.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df2.info()\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HR ADMINISTRATOR/MARKETING ASSOCIATE\\...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HR SPECIALIST, US HR OPERATIONS      ...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HR DIRECTOR       Summary      Over 2...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HR SPECIALIST       Summary    Dedica...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HR MANAGER         Skill Highlights  ...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Category\n",
       "0           HR ADMINISTRATOR/MARKETING ASSOCIATE\\...       HR\n",
       "1           HR SPECIALIST, US HR OPERATIONS      ...       HR\n",
       "2           HR DIRECTOR       Summary      Over 2...       HR\n",
       "3           HR SPECIALIST       Summary    Dedica...       HR\n",
       "4           HR MANAGER         Skill Highlights  ...       HR"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.drop(columns = ['Resume_html', 'ID'], inplace = True)\n",
    "df1.rename(columns={'Resume_str': 'Text'}, inplace=True)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Accountant' 'Advocate' 'Agriculture' 'Apparel' 'Architecture' 'Arts'\n",
      " 'Automobile' 'Aviation' 'Banking' 'Blockchain' 'BPO'\n",
      " 'Building and Construction' 'Business Analyst' 'Civil Engineer'\n",
      " 'Consultant' 'Data Science' 'Database' 'Designing' 'DevOps'\n",
      " 'Digital Media' 'DotNet Developer' 'Education' 'Electrical Engineering'\n",
      " 'ETL Developer' 'Finance' 'Food and Beverages' 'Health and Fitness'\n",
      " 'Human Resources' 'Information Technology' 'Java Developer' 'Management'\n",
      " 'Mechanical Engineer' 'Network Security Engineer' 'Operations Manager'\n",
      " 'PMO' 'Public Relations' 'Python Developer' 'React Developer' 'Sales'\n",
      " 'SAP Developer' 'SQL Developer' 'Testing' 'Web Designing']\n"
     ]
    }
   ],
   "source": [
    "print(df2['Category'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HR' 'DESIGNER' 'INFORMATION-TECHNOLOGY' 'TEACHER' 'ADVOCATE'\n",
      " 'BUSINESS-DEVELOPMENT' 'HEALTHCARE' 'FITNESS' 'AGRICULTURE' 'BPO' 'SALES'\n",
      " 'CONSULTANT' 'DIGITAL-MEDIA' 'AUTOMOBILE' 'CHEF' 'FINANCE' 'APPAREL'\n",
      " 'ENGINEERING' 'ACCOUNTANT' 'CONSTRUCTION' 'PUBLIC-RELATIONS' 'BANKING'\n",
      " 'ARTS' 'AVIATION']\n"
     ]
    }
   ],
   "source": [
    "print(df1['Category'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_category = {\n",
    "    'ACCOUNTANT': 'Accountant',\n",
    "    'ADVOCATE': 'Advocate',\n",
    "    'AGRICULTURE': 'Agriculture',\n",
    "    'APPAREL': 'Apparel',\n",
    "    'ARTS': 'Arts',\n",
    "    'AUTOMOBILE': 'Automobile',\n",
    "    'AVIATION': 'Aviation',\n",
    "    'BANKING': 'Banking',\n",
    "    'BPO': 'BPO',\n",
    "    'CONSTRUCTION': 'Building and Construction',\n",
    "    'CONSULTANT': 'Consultant',\n",
    "    'DIGITAL-MEDIA': 'Digital Media',\n",
    "    'SALES': 'Sales',\n",
    "    'FINANCE': 'Finance',\n",
    "    'PUBLIC-RELATIONS': 'Public Relations',\n",
    "    'INFORMATION-TECHNOLOGY': 'Information Technology',\n",
    "    'TEACHER': 'Education',\n",
    "    'HR': 'Human Resources',\n",
    "    'DESIGNER': 'Designing',\n",
    "    'BUSINESS-DEVELOPMENT': 'Business Analyst',\n",
    "    'HEALTHCARE': 'Health and Fitness',\n",
    "    'FITNESS': 'Health and Fitness',\n",
    "    'ACCOUNTANT': 'Accountant',\n",
    "    'ARTS': 'Arts',\n",
    "\n",
    "    'ENGINEERING': 'Engineer',  #new class\n",
    "    'CHEF': 'Chef'              #new class\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Category'] = df1['Category'].map(map_category)\n",
    "df = pd.concat([df2, df1], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15873 entries, 0 to 15872\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Category  15873 non-null  object\n",
      " 1   Text      15873 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 248.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of valid English words\n",
    "english_words = set(words.words())\n",
    "\n",
    "# Get a list of stop word\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "# Initialize the stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, remove_numbers=True, use_dictionary=True, use_lemmatization=False, use_stemming=True):\n",
    "    \"\"\"\n",
    "    Preprocesses the text: \n",
    "    - Converts to lowercase\n",
    "    - Removes punctuation\n",
    "    - Tokenizes\n",
    "    - Removes stopwords\n",
    "    - Removes words with numbers (if enabled)\n",
    "    - Uses dictionary filtering (if enabled)\n",
    "    - Applies lemmatization or stemming based on parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    text = text.lower()                         # Convert to lowercase\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)         # TODO non ho capito perchè commantando diminuiscono i token     # Remove all punctuation  \n",
    "    text = re.sub(r'\\s+', ' ', text).strip()    # Remove multiple spaces\n",
    "    \n",
    "    tokens = word_tokenize(text) # Tokenize the text\n",
    "\n",
    "    processed_tokens = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        # Remove words containing numbers (if enabled)\n",
    "        if remove_numbers and any(char.isdigit() for char in token):\n",
    "            continue\n",
    "\n",
    "        # Dictionary filtering (if enabled)\n",
    "        if use_dictionary and token not in english_words:\n",
    "            continue\n",
    "\n",
    "        # Remove stopwords\n",
    "        if token in stop_words:\n",
    "            continue\n",
    "\n",
    "        if use_lemmatization:\n",
    "            token = lemmatizer.lemmatize(token)\n",
    "        elif use_stemming:\n",
    "            token = stemmer.stem(token)\n",
    "\n",
    "        processed_tokens.append(token)\n",
    "        \n",
    "        # Check if the token contains only letters/numbers\n",
    "        # if re.fullmatch(r'[a-zA-Z0-9]+', token):              # not usefull if use_dictionary = True\n",
    "\n",
    "        # Exclude stopwords\n",
    "        # if token not in stop_words and not token.isdigit():\n",
    "        #     # If requested, check if it is in the English dictionary or is a number\n",
    "        #     if use_dictionary:\n",
    "        #         if token in english_words:   # TODO probably, in classification, it's not necessary to have the digits\n",
    "        #             # stemmed = stemmer.stem(token)\n",
    "        #             lemmed = lemmatizer.lemmatize(token)      # TODO try lemmatizer instead stemmer, it could improve performance\n",
    "        #             processed_tokens.append(lemmed)\n",
    "        #     else:\n",
    "        #         # stemmed = stemmer.stem(token)\n",
    "        #         lemmed = lemmatizer.lemmatize(token)          # TODO try lemmatizer instead stemmer, it could improve performance\n",
    "        #         processed_tokens.append(lemmed)\n",
    "        # # If the token is not valid, discard it\n",
    "\n",
    "    \n",
    "    #tokens = remove_non_english(tokens)    # Remove non-English words\n",
    "    \n",
    "    return ' '.join(processed_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm  # Library for the progress bar\n",
    "\n",
    "def preprocess_text_with_progress(df, column_name, **kwargs):\n",
    "    \"\"\"\n",
    "    Applies preprocess_text to a DataFrame column with a progress bar.\n",
    "    \n",
    "    Args:\n",
    "    - df (pd.DataFrame): DataFrame containing the data\n",
    "    - column_name (str): Name of the column to preprocess\n",
    "    - kwargs: Parameters to pass to the preprocess_text function\n",
    "    \n",
    "    Returns:\n",
    "    - pd.Series: Series containing the preprocessed texts\n",
    "    \"\"\"\n",
    "    tqdm.pandas(desc=\"Processing Resumes\")  # Enable tqdm for Pandas\n",
    "    return df[column_name].progress_apply(lambda x: preprocess_text(x, **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "parameter_sets = [\n",
    "    #{\"remove_numbers\": True, \"use_dictionary\": False, \"use_lemmatization\": True, \"use_stemming\": False},\n",
    "    #{\"remove_numbers\": True, \"use_dictionary\": False, \"use_lemmatization\": False, \"use_stemming\": True},\n",
    "    #{\"remove_numbers\": False, \"use_dictionary\": True, \"use_lemmatization\": True, \"use_stemming\": False},\n",
    "    #{\"remove_numbers\": False, \"use_dictionary\": True, \"use_lemmatization\": False, \"use_stemming\": True},\n",
    "    {\"remove_numbers\": True, \"use_dictionary\": True, \"use_lemmatization\": True, \"use_stemming\": False},\n",
    "    #{\"remove_numbers\": True, \"use_dictionary\": True, \"use_lemmatization\": False, \"use_stemming\": True},\n",
    "    #{\"remove_numbers\": False, \"use_dictionary\": False, \"use_lemmatization\": True, \"use_stemming\": False},\n",
    "    #{\"remove_numbers\": False, \"use_dictionary\": False, \"use_lemmatization\": False, \"use_stemming\": True},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Resumes: 100%|██████████| 15873/15873 [02:54<00:00, 90.84it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed DataFrame saved as: processed_data\\Resume_processed_remove_numbers=True_use_dictionary=True_use_lemmatization=True_use_stemming=False.csv\n"
     ]
    }
   ],
   "source": [
    "for params in parameter_sets:\n",
    "    # Create a copy of the original DataFrame\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Apply preprocessing with the current parameter combination\n",
    "    df_copy['Text'] = preprocess_text_with_progress(df_copy, 'Text', **params)\n",
    "\n",
    "    # Define the folder where CSV files will be saved\n",
    "    output_folder = \"processed_data\"\n",
    "    \n",
    "    # Ensure the folder exists (create it if necessary)\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Generate the full path for saving the file\n",
    "    filename = os.path.join(output_folder, \"Resume_processed_\" + \"_\".join([f\"{key}={value}\" for key, value in params.items()]) + \".csv\")\n",
    "    \n",
    "    # Save the DataFrame to the specified folder\n",
    "    df_copy.to_csv(filename, index=False)\n",
    "\n",
    "    print(f\"Processed DataFrame saved as: {filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
