{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\filip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\filip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\filip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\filip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import os\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Download necessary NLTK packages\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('words')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\filip/nltk_data',\n",
       " 'c:\\\\Users\\\\filip\\\\anaconda3\\\\envs\\\\DMML\\\\nltk_data',\n",
       " 'c:\\\\Users\\\\filip\\\\anaconda3\\\\envs\\\\DMML\\\\share\\\\nltk_data',\n",
       " 'c:\\\\Users\\\\filip\\\\anaconda3\\\\envs\\\\DMML\\\\lib\\\\nltk_data',\n",
       " 'C:\\\\Users\\\\filip\\\\AppData\\\\Roaming\\\\nltk_data',\n",
       " 'C:\\\\nltk_data',\n",
       " 'D:\\\\nltk_data',\n",
       " 'E:\\\\nltk_data']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.data.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Resume_str</th>\n",
       "      <th>Resume_html</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16852973</td>\n",
       "      <td>HR ADMINISTRATOR/MARKETING ASSOCIATE\\...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22323967</td>\n",
       "      <td>HR SPECIALIST, US HR OPERATIONS      ...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33176873</td>\n",
       "      <td>HR DIRECTOR       Summary      Over 2...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27018550</td>\n",
       "      <td>HR SPECIALIST       Summary    Dedica...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17812897</td>\n",
       "      <td>HR MANAGER         Skill Highlights  ...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                         Resume_str  \\\n",
       "0  16852973           HR ADMINISTRATOR/MARKETING ASSOCIATE\\...   \n",
       "1  22323967           HR SPECIALIST, US HR OPERATIONS      ...   \n",
       "2  33176873           HR DIRECTOR       Summary      Over 2...   \n",
       "3  27018550           HR SPECIALIST       Summary    Dedica...   \n",
       "4  17812897           HR MANAGER         Skill Highlights  ...   \n",
       "\n",
       "                                         Resume_html Category  \n",
       "0  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
       "1  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
       "2  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
       "3  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
       "4  <div class=\"fontsize fontface vmargins hmargin...       HR  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../dataset/Resumes/data/Resume.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the dataset consists of four columns: ID, Resume_str, Resume_html, and Category. For our purpose, we don’t need the column containing the HTML code, as the plain text string is sufficient. Therefore, we will remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Resume_str</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16852973</td>\n",
       "      <td>HR ADMINISTRATOR/MARKETING ASSOCIATE\\...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22323967</td>\n",
       "      <td>HR SPECIALIST, US HR OPERATIONS      ...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33176873</td>\n",
       "      <td>HR DIRECTOR       Summary      Over 2...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27018550</td>\n",
       "      <td>HR SPECIALIST       Summary    Dedica...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17812897</td>\n",
       "      <td>HR MANAGER         Skill Highlights  ...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                         Resume_str Category\n",
       "0  16852973           HR ADMINISTRATOR/MARKETING ASSOCIATE\\...       HR\n",
       "1  22323967           HR SPECIALIST, US HR OPERATIONS      ...       HR\n",
       "2  33176873           HR DIRECTOR       Summary      Over 2...       HR\n",
       "3  27018550           HR SPECIALIST       Summary    Dedica...       HR\n",
       "4  17812897           HR MANAGER         Skill Highlights  ...       HR"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns = ['Resume_html'], inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2484 entries, 0 to 2483\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   ID          2484 non-null   int64 \n",
      " 1   Resume_str  2484 non-null   object\n",
      " 2   Category    2484 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 58.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Resume_str    1\n",
       "Category      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From the data visualization (Visualization.ipynb), we noticed that there is an empty resume in the dataset\n",
    "df.select_dtypes(include='object').apply(lambda col: col.str.strip() == '').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Resume_str'].str.strip() != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2483 entries, 0 to 2483\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   ID          2483 non-null   int64 \n",
      " 1   Resume_str  2483 non-null   object\n",
      " 2   Category    2483 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 77.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics of Word Count in Resumes:\n",
      "Minimum      : 113.0\n",
      "1st Quartile : 651.0\n",
      "Median       : 757.0\n",
      "3rd Quartile : 933.0\n",
      "Maximum      : 5190.0\n",
      "Mean         : 811.65\n",
      "IQR (Q3 - Q1): 282.0\n"
     ]
    }
   ],
   "source": [
    "word_count = df['Resume_str'].apply(lambda x: len(str(x).split()))      # For each resume, \"word_count\" contains the number of words\n",
    "\n",
    "desc = word_count.describe()\n",
    "q1 = word_count.quantile(0.25)\n",
    "q3 = word_count.quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "\n",
    "print(\"Statistics of Word Count in Resumes:\")\n",
    "print(f\"Minimum      : {desc['min']}\")\n",
    "print(f\"1st Quartile : {q1}\")\n",
    "print(f\"Median       : {desc['50%']}\")\n",
    "print(f\"3rd Quartile : {q3}\")\n",
    "print(f\"Maximum      : {desc['max']}\")\n",
    "print(f\"Mean         : {desc['mean']:.2f}\")\n",
    "print(f\"IQR (Q3 - Q1): {iqr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of stop word\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "# Initialize the stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, remove_stopword=True, use_lemmatization=True, use_stemming=False):\n",
    "    \"\"\"\n",
    "    Preprocesses the text: \n",
    "    - Converts to lowercase\n",
    "    - Removes punctuation\n",
    "    - Removes underscore\n",
    "    - Removes multiple spaces\n",
    "    - Tokenizes\n",
    "    - Removes tokens with numbers\n",
    "    - Removes stopwords based on parameter\n",
    "    - Applies lemmatization or stemming based on parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    text = text.lower()                     # Convert to lowercase\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)    # Remove all punctuation (\\w = a-z, A-Z, 0-9 and underscore)\n",
    "    text = re.sub(r'_', ' ', text)          # Remove underscore\n",
    "    text = re.sub('\\s+', ' ', text)         # Remove multiple spaces\n",
    "\n",
    "    tokens = word_tokenize(text)            # Tokenize the text\n",
    "\n",
    "    processed_tokens = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        # Remove words containing numbers\n",
    "        if any(char.isdigit() for char in token):\n",
    "            continue\n",
    "\n",
    "        # Remove stopwords based on parameter\n",
    "        if remove_stopword and (token in stop_words):\n",
    "            continue\n",
    "\n",
    "        # Applies lemmatization or stemming based on parameters\n",
    "        if use_lemmatization:\n",
    "            token = lemmatizer.lemmatize(token)\n",
    "        if use_stemming:\n",
    "            token = stemmer.stem(token)\n",
    "\n",
    "        processed_tokens.append(token)\n",
    "    \n",
    "    return ' '.join(processed_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text_with_progress(df, column_name, **kwargs):\n",
    "    \"\"\" \n",
    "    Function to preprocess text column with a progress bar \n",
    "    \"\"\"\n",
    "                \n",
    "    tqdm.pandas(desc=\"Processing Resumes\")  # Integrate tqdm progress bar into pandas\n",
    "    return df[column_name].progress_apply(lambda x: preprocess_text(x, **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_sets = [\n",
    "    {\"remove_stopword\": True, \"use_lemmatization\": True, \"use_stemming\": True},\n",
    "    {\"remove_stopword\": True, \"use_lemmatization\": True, \"use_stemming\": False},\n",
    "    {\"remove_stopword\": True, \"use_lemmatization\": False, \"use_stemming\": True},\n",
    "    {\"remove_stopword\": False, \"use_lemmatization\": False, \"use_stemming\": False},\n",
    "    {\"remove_stopword\": False, \"use_lemmatization\": True, \"use_stemming\": False}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Resumes:   0%|          | 0/1986 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Resumes: 100%|██████████| 1986/1986 [00:36<00:00, 54.44it/s]\n",
      "Processing Resumes: 100%|██████████| 497/497 [00:07<00:00, 67.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed DataFrame saved as: Resume_removeStopword_useLemm_useStemm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Resumes: 100%|██████████| 1986/1986 [00:11<00:00, 166.68it/s]\n",
      "Processing Resumes: 100%|██████████| 497/497 [00:02<00:00, 186.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed DataFrame saved as: Resume_removeStopword_useLemm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Resumes: 100%|██████████| 1986/1986 [00:25<00:00, 79.33it/s]\n",
      "Processing Resumes: 100%|██████████| 497/497 [00:07<00:00, 70.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed DataFrame saved as: Resume_removeStopword_useStemm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Resumes: 100%|██████████| 1986/1986 [00:07<00:00, 260.77it/s]\n",
      "Processing Resumes: 100%|██████████| 497/497 [00:01<00:00, 277.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed DataFrame saved as: Resume\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Resumes: 100%|██████████| 1986/1986 [00:16<00:00, 117.40it/s]\n",
      "Processing Resumes: 100%|██████████| 497/497 [00:03<00:00, 125.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed DataFrame saved as: Resume_useLemm\n"
     ]
    }
   ],
   "source": [
    "output_folder = \"processed_data\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42, stratify=df['Category'])\n",
    "\n",
    "for params in parameter_sets:\n",
    "    df_train_copy = df_train.copy()\n",
    "    df_test_copy = df_test.copy()\n",
    "    df_train_copy['Resume_str'] = preprocess_text_with_progress(df_train_copy, 'Resume_str', **params)\n",
    "    df_test_copy['Resume_str'] = preprocess_text_with_progress(df_test_copy, 'Resume_str', **params)\n",
    "\n",
    "    file_name = 'Resume'\n",
    "    if params[\"remove_stopword\"]:\n",
    "        file_name += '_removeStopword'\n",
    "    if params[\"use_lemmatization\"]:\n",
    "        file_name += '_useLemm'\n",
    "    if params[\"use_stemming\"]:\n",
    "        file_name += '_useStemm'\n",
    "\n",
    "    folder_path = os.path.join(output_folder, file_name)\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "    path = os.path.join(folder_path, 'train.csv')\n",
    "    df_train_copy.to_csv(path, index=False)\n",
    "\n",
    "    path = os.path.join(folder_path, 'test.csv')\n",
    "    df_test_copy.to_csv(path, index=False)\n",
    "\n",
    "    print(f\"Processed DataFrame saved as: {file_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DMML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
